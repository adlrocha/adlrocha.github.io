---
title: "The State of LLMs"
date: "2023-12-07"
draft: false
tags: [AI, research]
---

# The Current State of AI
> Or rather, my limited view from the outside.

I've been trying to stay up to date (at least at a high level) with all the new developments in the field of AI, but with a full-time job this is quite a challenge. This is even more of a challenge when your full-time job is not closely related with the field of AI. My only sources of information these days for all AI-related updates are Twitter and Hacker News, and to make matters worse my ML background is quite limited and goes back to my college years, so you can imagine that I understand just half of what I read.

However, in order to start getting up to speed with AI, I realized that it could be a good practice to share the things that I may have learnt that week related to AI (even if they are obvious for experts in the field). This will help me build a mental model of what the hell is happening with AI these days, and how it can be leveraged. "_Does this mean that we are back to weekly publications?"_ Hopefully. I really miss my weekly writing habit, and this is as good an excuse as any other.

![Kid learning about AI and looking at its bright future](../images/kid-ai.jpeg)
*Kid learning about AI and looking at its bright future - SDXL*

## A personal high-level overview
In these past few months that I've been paying a bit more of attention to the AI space, these are a few of the things that I've realized:
- __LLMs and foundational models are becoming a commodity__: Training an LLM from scratch is really expensive, and only a limited amount of companies with big pockets and access to a lot of hardware will be able to do so ([phi-2](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/), a "small" LLM with 2.7B parameters took Microsoft 14 days and 96 A100 GPUs). Fortunately, there are already [several open foundational models](https://github.com/eugeneyan/open-llms) out there. Developers, researches, and new startups have already done amazing things building upon existing open-source foundational models. These models can already have unprecedented impact, and become the core of really innovative new use cases.
- __Building narrow agents by fine-tuning foundational models is the next frontier__: While small teams and developers may not be able to train their own foundational models, they may still build really innovative models to solve specific problems. Companies like OpenAI or Google may be racing towards AGI, but I feel there's still a lot of value on solving niche day-to-day issues through AI and LLMs. For this, we don't need AGI or really strong foundational models, fine-tuned version of existing open-source foundational models may be just what that problem needs. By building really good task-specific models we may be building small agents that in the future are able to collaborate towards more complex tasks _(maybe this is the actual path towards AGI?)_. There already a good examples of companies being built on top of this task-specific agents like [Fixie.ai](https://fixie.ai/), for general agent building and orchestration, or [Luzia](https://www.luzia.com/en/), as a good example of a use-case specific agent built on top of foundational models.
- __Use cases are in exploration mode__: I don't know about you, but while the future use cases and impact of AI as a technology is way clearer than that of blockchain technology (obviously). I still feel we still are in a use case exploration phase for LLMs, generative models, and all the new innovations that are being released almost every day. Generative models are already creating breathtaking images and outstanding glimpses of real intelligence and creativity. We've found a new superpower, but I am not really sure if we have figured out the best way to use it. ChatGPT et. al are amazing co-pilots for our day-to-day, but they aren't yet as good as a good Google search or a well-thought and well-explained Stack Overflow post.
- __Production deployment of LLM-based apps will become an issue__: I remember that a few years ago there was a lot of AI innovative applications over Jupyter Notebooks. RL models that were beating humans on Atari games, image recognition on any kind of video, etc. While this is super useful for edge and narrow use cases, it may not fit the scalable deployments required for the kind of applications that are being envisioned now. I think one of the key challenges for AI in the short/mid-term may not be the performance or capabilities of AI models, but providing the infrastructure to deploy them in a scalable way. From GPUs, to model performance, networking, and load-balancing of the infrastructure.
- __We should worry about alignment__: But not only performance will be and issue, but also security. And I don't know about you, but this is one that really worries me. There are a lot of things that could go wrong security-wise and that we may not be aware of: from leaking personal information in models, to more catastrophic and existential risk-relate issues. The moment we start connecting complex AI models to the Internet and other real-time sources of information, and we offer them levers over the real world, things could get messy really quickly. As mentioned above, we found a new superpower of the likes of electricity, fire, or the Internet, and we know this could be huge, but we still don't know how to use it, and all the detrimental impact it may have. One of the reasons I decided to start getting up to speed with AI again is that I want to start contributing more actively to the problem of AI alignment.
- __We still need humans in the loop__: Generative models need new content to improve their performance, and according to recent studies, we may be running out of useful data to train these models. This means that AIs still need humans to create more data that they can consume to improve their training. So at least in the short-term, I still see big tech and AI models requiring humans as part of their supply chain.

## Any feedback?
I shared above an overview of what I think is the current state of development of AI. Again, I am not an expert on AI or ML, and I am just starting to peek this vast world, so any feedback or suggestions on how to improve my understanding along the way are more than welcome. Thank you for reading, and see you in the next post.
